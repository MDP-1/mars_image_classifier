{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apxs', 'apxs cal target', 'chemcam cal target', 'chemin minlet open', 'drill', 'drill holes', 'drt front', 'drt side', 'ground', 'horizon', 'inlet', 'mahli', 'mahli cal target', 'mastcam', 'mastcam cal target', 'observation tray', 'portion box', 'portion tube', 'portion tube opening', 'rems uv sensor', 'rover rear deck', 'scoop', 'sun', 'turret', 'wheel']\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24']\n",
      "Found 3746 validated image filenames belonging to 25 classes.\n",
      "Found 1640 validated image filenames belonging to 25 classes.\n",
      "Found 1305 validated image filenames belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING\n",
    "\n",
    "# Define Image/Save Directories\n",
    "common_path = \"/Users/michaelpatsais/Documents/Uni_work/Astrophysics/machine_learning/deep-learning-2024/Project/msl-images/\"\n",
    "# save_directory = \"\" # for saving plots\n",
    "\n",
    "idg = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "# LABELS DF\n",
    "image_classes = np.loadtxt(common_path + \"msl_synset_words-indexed.txt\", dtype = str, delimiter = \",\")\n",
    "labels_df = pd.DataFrame(image_classes, columns = [\"filename\", \"class\"])\n",
    "\n",
    "# extracting unique values from the \"class\" column of `labels_df` and converting them into a list.\n",
    "labels = labels_df[\"class\"].unique().tolist()\n",
    "labels = [x.strip() for x in labels]\n",
    "print(labels)\n",
    "\n",
    "# creating an array of integers from 0 to the length of the `labels` list to assign a numerical identifier to each unique label in the dataset.\n",
    "classes = np.arange(len(labels))\n",
    "classes = [str(x) for x in classes]\n",
    "print(classes)\n",
    "\n",
    "# training dataset\n",
    "train = np.loadtxt(common_path + \"train-calibrated-shuffled.txt\", dtype = str, delimiter = \" \")\n",
    "train_df = pd.DataFrame(train, columns = [\"filename\", \"class\"])\n",
    "train_ds = idg.flow_from_dataframe(dataframe = train_df, directory = common_path, classes = classes, batch_size = 100)\n",
    "\n",
    "# VAL dataset\n",
    "val = np.loadtxt(common_path + \"val-calibrated-shuffled.txt\", dtype = str, delimiter = \" \")\n",
    "val_df = pd.DataFrame(val, columns = [\"filename\", \"class\"])\n",
    "val_ds = idg.flow_from_dataframe(dataframe = val_df, directory = common_path, classes = classes, batch_size = 100)\n",
    "\n",
    "# TEST dataset\n",
    "test = np.loadtxt(common_path + \"test-calibrated-shuffled.txt\", dtype = str, delimiter = \" \")\n",
    "test_df = pd.DataFrame(test, columns = [\"filename\", \"class\"])\n",
    "test_ds = idg.flow_from_dataframe(dataframe = test_df, directory = common_path, classes = classes, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MODEL CONFIGURATION\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "dropout_val = 0.4\n",
    "\n",
    "# image dimensions\n",
    "xpix = train_ds[0][0][0].shape[0] # [batch][image_data/label][image]\n",
    "ypix = train_ds[0][0][0].shape[1]\n",
    "zpix = train_ds[0][0][0].shape[2]\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (5, 5), activation='relu', input_shape=(xpix, ypix, zpix)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(dropout_val),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "history  = model.fit(train_ds, validation_data=val_ds, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy & Loss\n",
    "\n",
    "print(\"  N(Epochs)        = \", epochs)\n",
    "print(\"  accuracy (train) = \", history.history['accuracy'])\n",
    "print(\"  accuracy (test)  = \", history.history['val_accuracy'])\n",
    "\n",
    "plt.plot(history.history['accuracy']) # 'accuracy'\n",
    "plt.plot(history.history['val_accuracy']) # 'val_accuracy'\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='lower right')\n",
    "# plt.savefig(save_directory + \"/Multi_Classification_model_accuracy.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"  loss (train)     = \", history.history['loss'])\n",
    "print(\"  loss (test)      = \", history.history['val_loss'])\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss']) # 'loss'\n",
    "plt.plot(history.history['val_loss']) # 'val_loss'\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper right')\n",
    "# plt.savefig(save_directory + \"/Multi_Classification_model_loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting image of each Classification\n",
    "\n",
    "predictions = model.predict(test_ds)\n",
    "\n",
    "# combining batches so that test and prediction images line up\n",
    "all_images = np.concatenate([test_ds[batch][0] for batch in range(len(test_ds))])\n",
    "all_images_data = np.concatenate([test_ds[batch][1] for batch in range(len(test_ds))])\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize = (20,20))\n",
    "            \n",
    "for i in range(25): # a counter that represents the classfication we want to print\n",
    "    ax = axes[i//5, i%5] # calculating the subplot to print to\n",
    "    for image in range(len(all_images_data)):\n",
    "        if (np.argmax(all_images_data[image]) != i): # if the image is not of the right classification, it is skipped\n",
    "            continue\n",
    "        else:\n",
    "            ax.set_title(f\"P:{labels[np.argmax(predictions[image])]},T:{labels[i]}\") # right classification is printed, with its label and corresponding prediction\n",
    "            ax.imshow(all_images[image])\n",
    "            break # break to move on to next classification\n",
    "        \n",
    "plt.tight_layout()        \n",
    "# plt.savefig(save_directory + \"/2b.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating accuracy of predictions\n",
    "\n",
    "# Checking for imbalance in number of images per class in train and test data \n",
    "# class_amounts_train = train_df[\"class\"].value_counts().to_dict()\n",
    "# class_amounts_test = test_df[\"class\"].value_counts().to_dict()\n",
    "# print(class_amounts_train)\n",
    "# print(class_amounts_test)\n",
    "\n",
    "classifications = [[] for _ in range(25)] # creating an empty list for each classification, to store correct/incorrect predictions\n",
    "\n",
    "for i, image_data in enumerate(all_images_data): # for each image, its label and prediction are stored in variables\n",
    "    true_val = int(np.argmax(image_data)) \n",
    "    pred_val = int(np.argmax(predictions[i]))\n",
    "    \n",
    "    if true_val == pred_val: #if the variables match, the list of the classification will be appended by a correct/incorrect \n",
    "        classifications[true_val].append(\"correct\")\n",
    "    else:\n",
    "        classifications[true_val].append(\"incorrect\")\n",
    "\n",
    "correct = [classification.count(\"correct\") for classification in classifications] #for each classification list, the number of correct predictions are stored \n",
    "incorrect = [classification.count(\"incorrect\") for classification in classifications] #for each classification list, the number of incorrect predictions are stored\n",
    "\n",
    "x_axis = np.arange(len(classifications))\n",
    "\n",
    "# plotting the correcct/incorrect amounts per classification as a bar chart\n",
    "plt.figure()\n",
    "plt.bar(x_axis, correct, color = \"blue\")\n",
    "plt.bar(x_axis, incorrect, bottom = correct, color = \"red\")\n",
    "plt.title('model accuracy bar chart')\n",
    "plt.ylabel('No. of images')\n",
    "plt.xlabel('Classification')\n",
    "plt.xticks(range(len(classes)))\n",
    "plt.legend(['correct', 'incorrect'], loc='upper left')\n",
    "# plt.savefig(save_directory + \"/2c_accuracy_bar.png\")\n",
    "plt.show()\n",
    "\n",
    "# calculating accuracy percentage per class\n",
    "accuracy_perc = []\n",
    "\n",
    "for correct_count, incorrect_count in zip(correct, incorrect):\n",
    "    total = correct_count+incorrect_count\n",
    "    if total > 0:\n",
    "        acc = correct_count/total\n",
    "    else: \n",
    "        acc = 0 \n",
    "    accuracy_perc.append(acc)\n",
    "\n",
    "plt.plot(accuracy_perc)\n",
    "plt.title('model accuracy percentage')\n",
    "plt.ylabel('Accuracy Percentage')\n",
    "plt.xlabel('Classification')\n",
    "plt.xticks(range(len(classes)))\n",
    "# plt.savefig(save_directory + \"/2c_accuracy_perc.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Datasciencevenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
